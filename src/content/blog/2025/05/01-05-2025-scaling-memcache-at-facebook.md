---
title: 'Facebook รองรับ Request Billion/Sec โดยใช้ Memcached ได้อย่างไร?'
description: 'Facebook รองรับ Request Billion/Sec โดยใช้ Memcached ได้อย่างไร?'
pubDate: 'May 01 2025'
heroImage: '/2025/05/65ae96c9-5f02-4c83-a35d-d400efcda942.png'
draft: true
---

> Note: Paper นี้ public เมื่อตอนปี 2013 นะ

มีความจริงสองข้อเกี่ยวกับการให้บริการ social network ในระดับของ Facebook:
* หนึ่ง ระบบต้องไม่ล่ม
* สอง ระบบต้องไม่ช้า
.
สองปัจจัยนี้เป็นตัวตัดสินว่าผู้คนจะยังอยู่ใน social network ของคุณหรือไม่แม้เพียงไม่กี่คนจะเลิกใช้งาน ก็สามารถส่งผลต่อผู้ใช้งานทั้งหมดได้ เพราะผู้ใช้มีความเชื่อมโยงถึงกันผู้คนส่วนใหญ่ใช้งานออนไลน์เพราะเพื่อนหรือครอบครัวของพวกเขาออนไลน์อยู่ ซึ่งทำให้เกิด Domino effectถ้าผู้ใช้คนหนึ่งหลุดออกจากระบบเพราะปัญหา บางทีผู้ใช้อื่นก็อาจจะออกตามไปด้วย
Facebook ต้องรับมือกับปัญหาเหล่านี้ตั้งแต่เริ่มต้น เนื่องจากความนิยมที่เพิ่มขึ้นอย่างรวดเร็วในทุกช่วงเวลา มีผู้คนนับล้านเข้าถึง Facebook จากทั่วโลก
.
ในมุมมองของการออกแบบ software นี่หมายถึงความต้องการสำคัญบางประการ:
* Facebook ต้องรองรับ  real-time communication
* ต้องสามารถรวมข้อมูล (content aggregation) ได้แบบ on-the-fly
* ขยายระบบให้รองรับ request จากผู้ใช้ได้หลักพันล้านครั้ง
* เก็บข้อมูลหลายล้านล้านรายการไว้ในหลาย geographic locations
.
เพื่อบรรลุเป้าหมายเหล่านี้ Facebook ได้นำ Memcached เวอร์ชัน open-source มาใช้ และพัฒนาต่อยอดเพื่อสร้างระบบ distributed key-value storeเวอร์ชันที่ถูกปรับปรุงนี้มีชื่อว่า Memcache
ในบทความนี้ เราจะมาดูกันว่า Facebook แก้ไขปัญหาหลากหลายในการปรับขนาด memcached เพื่อรองรับ request หลายพันล้านครั้งต่อวินาทีได้อย่างไร
.
Introduction to Memcached
Memcached คือ in-memory key-value store ที่รองรับคำสั่งพื้นฐานอย่าง set, get และ deleteเวอร์ชัน open-source จะทำงานเป็น hash table แบบ in-memory บนเครื่องเดียว
Engineer ของ Facebook ได้นำเวอร์ชันนี้มาเป็นพื้นฐานในการสร้างระบบ distributed key-value store ที่เรียกว่า Memcache
กล่าวอีกอย่าง “Memcached” หมายถึง source code หรือ binary ที่กำลังทำงาน ในขณะที่ “Memcache” หมายถึงระบบ distributed ที่อยู่เบื้องหลัง
ในเชิงเทคนิค Facebook ใช้ Memcache อยู่สองรูปแบบหลัก:
.
Query Cache
หน้าที่ของ query cache คือช่วยลดภาระของ database หลักที่เป็น source-of-truthในโหมดนี้ Facebook ใช้ Memcache เป็น look-aside cache ที่เติมข้อมูลตาม request หรือที่เรียกว่า cache-aside pattern
[แผนภาพด้านล่าง]แสดงวิธีการทำงานของ look-aside cache สำหรับเส้นทางการอ่านและเขียนข้อมูล (read และ write path)
สำหรับ read path จะใช้ cache ที่โหลดข้อมูลตาม request นั่นหมายความว่าข้อมูลจะถูกโหลดเข้า cache ก็ต่อเมื่อ client ขอข้อมูลนั้น
ก่อนที่จะ serving request, client จะตรวจสอบ cache ก่อน ถ้าไม่พบข้อมูล (cache miss) client จะไปดึงข้อมูลจาก database และอัปเดตเข้า cache
เส้นทางของการเขียน (write path) มีวิธีที่น่าสนใจมากกว่าในการอัปเดตข้อมูล
.เมื่อ key ใด key หนึ่งถูกอัปเดตใน database ระบบจะไม่อัปเดตข้อมูลใน cache โดยตรง แต่จะลบข้อมูลของ key นั้นออกจาก cache ไปเลยกระบวนการนี้เรียกว่า cache invalidation
.
ด้วยการลบ entry ใน cache ระบบจะมั่นใจได้ว่าครั้งต่อไปที่ client ขอข้อมูล key นั้น จะเกิด cache miss และจำเป็นต้องไปดึงข้อมูลล่าสุดจาก databaseวิธีนี้ช่วยให้ข้อมูลใน cache และใน database มีความสอดคล้องกัน (consistency)
.
Generic Cache
Facebook ยังใช้ Memcache เป็น key-value store สำหรับวัตถุประสงค์ทั่วไปด้วยสิ่งนี้ช่วยให้ทีมต่าง ๆ ภายในองค์กรสามารถใช้ Memcache เพื่อเก็บผลลัพธ์ที่คำนวณไว้ล่วงหน้า ซึ่งเกิดจากอัลกอริธึม machine learning ที่ใช้ทรัพยากรมาก
เมื่อเก็บผลลัพธ์ที่คำนวณไว้แล้วใน Memcache แอปพลิเคชันอื่น ๆ ก็สามารถเข้าถึงข้อมูลเหล่านั้นได้อย่างรวดเร็วและง่ายดาย
แนวทางนี้มีข้อดีหลายประการ เช่น ประสิทธิภาพที่ดีขึ้น และการใช้ทรัพยากรที่เหมาะสมยิ่งขึ้น
.
High-Level Architecture of Facebook
Architecture ของ Facebook ถูกออกแบบมาเพื่อรองรับขนาดระบบที่ใหญ่มหาศาลและการเข้าถึงจากทั่วโลก
ในช่วงที่ Facebook นำ Memcached มาใช้งาน high-level architecture ของระบบประกอบด้วยส่วนสำคัญ 3 ส่วน:
.
1 - Regions
Facebook วางเซิร์ฟเวอร์ไว้ในหลายตำแหน่งทั่วโลก ซึ่งเรียกว่า regionsregions แบ่งออกเป็นสองประเภท:
* Primary Region: รับผิดชอบการจัดการข้อมูลและรับโหลดจากผู้ใช้ส่วนใหญ่
* Secondary Region: กระจายอยู่ทั่วโลก เพื่อเพิ่ม redundancy, การกระจายโหลด และประสิทธิภาพสำหรับผู้ใช้ในพื้นที่ต่าง ๆ
.
แต่ละ region ไม่ว่าจะเป็น primary หรือ secondary จะมี frontend cluster หลายชุด และมี storage cluster หนึ่งชุด

2 - Frontend Clustersภายในแต่ละ region, Facebook ใช้ frontend cluster เพื่อจัดการ request จากผู้ใช้และให้บริการเนื้อหา
.frontend cluster ประกอบด้วยองค์ประกอบหลัก 2 อย่าง:
* Web Servers: เซิร์ฟเวอร์เหล่านี้รับผิดชอบในการประมวลผล request จากผู้ใช้, แสดงผลหน้าเพจ และ delivering content ให้ผู้ใช้
* Memcache Servers: ทำหน้าที่เป็น distributed caching layer ที่เก็บข้อมูลที่ถูกเรียกใช้งานบ่อย ๆ ไว้ใน memory เพื่อให้ดึงข้อมูลได้เร็วขึ้น
.
frontend cluster ถูกออกแบบให้สามารถ horizontally scaling ตามความต้องการได้เมื่อมีการใช้งานเพิ่มขึ้น Facebook ก็สามารถเพิ่ม web server และ Memcache server เข้าไปใน cluster ได้ เพื่อรองรับโหลดที่เพิ่มขึ้น
.————————
3 - Storage Clusterศูนย์กลางของแต่ละ region คือ storage clustercluster นี้เป็นที่อยู่ของฐานข้อมูลหลัก (source-of-truth database) ซึ่งเก็บสำเนาข้อมูลที่แท้จริงของระบบ Facebook
storage cluster ทำหน้าที่รักษาความสอดคล้องของข้อมูล (consistency), ความทนทาน (durability), และความน่าเชื่อถือ (reliability)
โดยการจำลองข้อมูล (replication) ข้ามหลาย region และใช้สถาปัตยกรรมแบบ primary-secondary, Facebook จึงสามารถสร้างความพร้อมใช้งานสูง (high availability) และความสามารถในการทนต่อความล้มเหลว (fault tolerance) ได้
แผนภาพด้านล่างแสดงภาพรวมของสถาปัตยกรรมนี้ในระดับสูง

หนึ่งในแนวคิดหลักที่ Facebook ยึดถือคือ ความยินดีที่จะให้บริการข้อมูลที่อาจล้าสมัยเล็กน้อย แทนที่จะเพิ่มภาระให้ backend มากเกินไปแทนที่จะพยายามทำให้ข้อมูลสอดคล้องสมบูรณ์แบบตลอดเวลา Facebook ยอมรับว่าผู้ใช้อาจเห็นข้อมูลเก่าบ้างบางเวลา
แนวทางนี้ช่วยให้ Facebook สามารถรองรับการใช้งานจำนวนมาก โดยไม่ทำให้ระบบ backend พังเพราะรับโหลดไม่ไหว
เพื่อให้สถาปัตยกรรมนี้สามารถทำงานได้ในระดับที่ไม่เคยมีมาก่อน เช่น รองรับคำร้องขอหลายพันล้านครั้งต่อวัน Facebook ต้องแก้ไขปัญหาหลายด้าน เช่น:
* การจัดการ latency และความล้มเหลวภายใน cluster
* การจัดการ replication ของข้อมูลภายใน region
* การจัดการความสอดคล้องของข้อมูลข้าม region
ในหัวข้อถัดไป เราจะมาดูกันว่า Facebook จัดการกับแต่ละปัญหาเหล่านี้อย่างไร

ความท้าทายภายใน Cluster
เป้าหมายสำคัญ 3 ข้อสำหรับการทำงานภายใน cluster คือ:
* ลด latency
* ลดภาระบนฐานข้อมูล
* จัดการกับความล้มเหลว

1 - ลด Latency
อย่างที่กล่าวไปก่อนหน้านี้ ทุก frontend cluster ประกอบด้วย Memcached server หลายร้อยตัว และข้อมูลถูกกระจายไปยังเซิร์ฟเวอร์เหล่านี้ด้วยเทคนิคอย่าง Consistent Hashing
อ้างอิงเพิ่มเติม Consistent Hashing คือเทคนิคที่ใช้กระจาย key ไปยังหลาย node โดยลดผลกระทบจากการเพิ่มหรือลด nodeเมื่อ node ตัวหนึ่งล่มหรือมีการเพิ่ม node ใหม่ Consistent Hashing จะทำให้ต้องย้าย key เพียงบางส่วนเท่านั้น แทนที่จะต้องย้ายทั้งหมด
แผนภาพจะแสดงแนวคิดของ Consistent Hashing โดย key จะถูกแมปเข้ากับตำแหน่งในวงกลม และ node ต่าง ๆ จะถูกจัดวางไว้ในวงกลมนั้นแต่ละ key จะถูกแมปไปยัง node ที่อยู่ใกล้ที่สุดในทิศตามเข็มนาฬิกา

ในระดับของ Facebook การร้องขอจากเว็บเพียงคำขอเดียวสามารถกระตุ้นคำร้องขอข้อมูลจาก Memcached server ได้หลายร้อยครั้ง
ลองนึกถึงสถานการณ์ที่ผู้ใช้โหลดหน้าเพจยอดนิยมที่มีหลายโพสต์และคอมเมนต์แม้แต่คำร้องขอเพียงคำขอเดียว ก็อาจทำให้ web server ต้องเชื่อมต่อกับ Memcached หลายตัวในเวลาสั้น ๆ เพื่อโหลดข้อมูลที่ต้องใช้
การดึงข้อมูลจำนวนมากนี้เกิดขึ้นไม่เพียงแค่ตอนที่เกิด cache hit เท่านั้น แต่ยังเกิดตอน cache miss ด้วยผลลัพธ์ก็คือ Memcached server หนึ่งตัวสามารถกลายเป็นคอขวด (bottleneck) ให้กับ web server จำนวนมาก ซึ่งจะเพิ่ม latency และลดประสิทธิภาพโดยรวม
เพื่อหลีกเลี่ยงสถานการณ์แบบนี้ Facebook ใช้กลยุทธ์สำคัญสองอย่าง ตามที่เห็นในแผนภาพ:

คำร้องขอแบบขนาน (Parallel Requests) และการรวมคำร้อง (Batching)
เพื่อให้เข้าใจแนวคิดของ parallel requests และ batching ลองเปรียบเทียบกับการไปซูเปอร์มาร์เก็ตหากคุณไปซื้อของทุกครั้งที่ต้องการสินค้าชิ้นเดียว จะเสียเวลามากทางที่ดีกว่าคือ วางแผนล่วงหน้าและซื้อของหลายอย่างพร้อมกันในการไปครั้งเดียว
แนวคิดเดียวกันนี้ถูกนำมาใช้กับการดึงข้อมูลใน frontend cluster ของ Facebookเพื่อเพิ่มประสิทธิภาพสูงสุด Facebook สร้าง Directed Acyclic Graph (DAG) เพื่อแทนความสัมพันธ์ระหว่างข้อมูลแต่ละชิ้น
DAG จะช่วยให้เข้าใจว่าข้อมูลใดสามารถดึงได้พร้อมกัน และข้อมูลใดต้องรอข้อมูลอื่นก่อนเมื่อวิเคราะห์ DAG แล้ว web server จะสามารถเรียงลำดับและจัดกลุ่มการดึงข้อมูลได้อย่างเหมาะสมข้อมูลที่ไม่มี dependency กันจะถูก grouped และร้องขอใน batch เดียวกัน
แน่นอน มาต่อจากหัวข้อ "Using UDP" เลย:

การใช้ UDP
Facebook ใช้กลยุทธ์ที่ชาญฉลาดในการเพิ่มประสิทธิภาพของการสื่อสารระหว่าง web server และ Memcache server
สำหรับคำร้องขอแบบดึงข้อมูล (fetch requests), Facebook ตั้งค่าให้ client ใช้ UDP แทน TCP
ตามที่คุณอาจทราบ UDP เป็นโปรโตคอลที่ไม่ต้องมีการเชื่อมต่อ (connectionless protocol) และเร็วกว่า TCP มากโดยการใช้ UDP, client สามารถส่งคำร้องขอ fetch ไปยัง Memcache server โดยมี overhead ด้านเครือข่ายน้อยลง ส่งผลให้คำร้องขอทำงานได้เร็วขึ้นและ latency ลดลง
อย่างไรก็ตาม UDP มีข้อเสีย คือ มันไม่รับประกันว่าข้อมูล (packet) จะถูกส่งถึงปลายทางหาก packet สูญหายระหว่างการส่ง UDP ก็ไม่มีระบบส่งซ้ำ (retransmission) ในตัว
เพื่อรับมือกับกรณีนี้ Facebook จัดการโดยถือว่าการสูญหายของ packet UDP เป็น cache miss ในฝั่ง clientหากไม่มีการตอบกลับภายในเวลาที่กำหนด client จะถือว่าข้อมูลไม่อยู่ใน cache และดำเนินการดึงข้อมูลจากแหล่งข้อมูลหลักแทน
สำหรับการอัปเดตและลบข้อมูล (update และ delete operations), Facebook ยังคงใช้ TCPเนื่องจาก TCP เป็นช่องทางการสื่อสารที่เชื่อถือได้ ซึ่งรับประกันว่า packet จะถูกส่งอย่างถูกต้องและเรียงลำดับจึงไม่จำเป็นต้องเพิ่มกลไก retry พิเศษ ซึ่งสำคัญอย่างยิ่งในกรณีที่มีการอัปเดตหรือลบข้อมูล
คำร้องขอทั้งหมดเหล่านี้จะผ่าน proxy พิเศษที่ชื่อว่า mcrouter ซึ่งทำงานอยู่บนเครื่องเดียวกับ web serverให้นึกว่า mcrouter คือคนกลางที่ทำหน้าที่หลายอย่าง เช่น การจัดการ serialization ของข้อมูล, การบีบอัดข้อมูล (compression), การกำหนดเส้นทาง (routing), การรวมคำร้อง (batching), และการจัดการข้อผิดพลาด (error handling)เราจะไปดูรายละเอียดของ mcrouter ในหัวข้อถัด ๆ ไป

2 - การลดโหลด (Reducing Load)
เป้าหมายหลักของ Memcache คือการลดภาระของฐานข้อมูล ด้วยการลดความถี่ในการดึงข้อมูลจากฐานข้อมูล
การใช้ Memcache แบบ look-aside cache ช่วยแก้ปัญหานี้ได้ดีมากแต่ในระดับของ Facebook ปัญหาที่เกี่ยวข้องกับการ cache สามารถเกิดขึ้นได้ง่าย เช่น:
* Stale Set: เกิดเมื่อ cache มีข้อมูลเก่า และไม่มีวิธีลบออกอย่างง่ายดาย
* Thundering Herd: เกิดขึ้นในสภาพแวดล้อมที่มีการเข้าถึงพร้อมกันสูง เมื่อเกิด cache miss แล้วมีคำร้องขอจำนวนมากถาโถมเข้าสู่ฐานข้อมูลพร้อมกัน
แผนภาพด้านล่างแสดงให้เห็นภาพรวมของปัญหาทั้งสองแบบนี้
เพื่อให้ปัญหาทั้งสองเกิดขึ้นน้อยที่สุด Facebook ใช้เทคนิคที่เรียกว่า leasing
Leasing ช่วยแก้ได้ทั้งปัญหา stale sets และ thundering herdsช่วยให้ Facebook ลดอัตราการ query ฐานข้อมูลจากสูงสุด 17,000 ครั้งต่อวินาที เหลือเพียง 1,300 ครั้งต่อวินาที

Stale Sets
ลองนึกว่ามี client ร้องขอข้อมูลจาก memcache ด้วย key ใด key หนึ่ง และเกิด cache missตอนนี้ responsibility ตกอยู่กับ client ในการไปดึงข้อมูลจากฐานข้อมูล และอัปเดตเข้า memcache เพื่อให้การร้องขอในอนาคตไม่เกิด cache miss ซ้ำ
กระบวนการนี้โดยทั่วไปก็ใช้ได้ดีแต่ในสภาพแวดล้อมที่มีการเข้าถึงพร้อมกันสูง ข้อมูลที่ client กำลังจะใส่เข้าไปใน cache อาจกลายเป็นข้อมูลเก่า (outdated) ก่อนที่มันจะถูกเขียนลง cache
Leasing เข้ามาแก้ปัญหานี้ได้
เมื่อเกิด cache miss, Memcache จะออก lease token (token 64-bit ที่ผูกกับ key นั้น) ให้กับ client รายใดรายหนึ่ง เพื่อมีสิทธิในการเขียนข้อมูลลง cache
เมื่อ client จะเขียนข้อมูล มันต้องแนบ token นี้มาด้วยMemcache จะตรวจสอบว่า token นั้นยัง valid หรือไม่ ก่อนจะยอมให้เขียนข้อมูลลง cacheหากข้อมูลถูก invalidated ไปก่อนแล้ว Memcache จะปฏิเสธคำร้องขอของ client โดย invalidating lease token
แผนภาพด้านล่างแสดงแนวคิดของ leasing ได้ชัดเจนยิ่งขึ้น

Thundering Herds
มีการดัดแปลงเล็กน้อยกับเทคนิค leasing เพื่อช่วยแก้ปัญหา thundering herd ด้วย
ในการดัดแปลงนี้ Memcache จะควบคุมความถี่ในการออก lease tokenเช่น ออก token ได้เพียงทุก ๆ 5 วินาทีต่อ key หนึ่ง key
หากมีคำร้องขอสำหรับ key เดียวกันเข้ามาภายใน 5 วินาทีนั้น Memcache จะส่ง response พิเศษกลับไปยัง client เพื่อให้รอและลองใหม่เพื่อป้องกันไม่ให้คำร้องขอเหล่านั้นพุ่งเข้าไปยังฐานข้อมูลโดยไม่จำเป็น
เนื่องจากมีความเป็นไปได้สูงว่าผู้ถือ lease token จะอัปเดต cache ในเร็ว ๆ นี้client ที่รอจะได้รับ cache hit ทันทีเมื่อ retry

3 - การจัดการความล้มเหลว (Handling Failures)
ในระบบที่มีขนาดมหาศาลอย่าง Facebook ความล้มเหลวเป็นสิ่งที่หลีกเลี่ยงไม่ได้
เมื่อมีผู้ใช้งานหลายล้านคน การที่ client ไม่สามารถดึงข้อมูลจาก Memcache ได้ จะสร้างภาระหนักให้กับ backend serverซึ่งอาจนำไปสู่ความล้มเหลวแบบลูกโซ่ในระบบ downstream อื่น ๆ ได้
แน่นอน มาต่อจากหัวข้อ "Two Levels of Failure" เลย:

สองระดับของความล้มเหลว (Two Levels of Failure)
Facebook พบกับความล้มเหลวหลัก ๆ อยู่สองระดับเมื่อพูดถึง Memcache:
* ความล้มเหลวขนาดเล็ก (Small-Scale Outages):เครื่องบางเครื่องอาจไม่สามารถเข้าถึงได้ เนื่องจากปัญหาด้านเครือข่ายหรือปัญหาเฉพาะในพื้นที่แม้เหตุการณ์ลักษณะนี้จะเกิดขึ้นในขอบเขตเล็ก แต่ก็ยังส่งผลกระทบต่อประสิทธิภาพโดยรวมของระบบ
* ความล้มเหลวขนาดใหญ่ (Widespread Outages):ในบางกรณี cluster ทั้งชุดอาจล่ม ส่งผลต่อ Memcache host เป็นจำนวนมากความล้มเหลวแบบนี้เป็นภัยคุกคามต่อเสถียรภาพและความพร้อมใช้งานของระบบอย่างมาก

การรับมือกับความล้มเหลวขนาดใหญ่ (Handling Widespread Outages)
เพื่อบรรเทาผลกระทบเมื่อ cluster ล่ม Facebook จะเบี่ยงเบนคำร้องขอจาก web server ไปยัง cluster อื่นที่ยังทำงานได้
ด้วยการกระจายโหลดในลักษณะนี้ Facebook ช่วยลดภาระของ cluster ที่มีปัญหา จนกว่าจะสามารถฟื้นฟูให้กลับมาใช้งานได้

การแก้ไขอัตโนมัติสำหรับความล้มเหลวขนาดเล็ก (Automated Remediation for Small Outages)
ในกรณีของความล้มเหลวขนาดเล็ก Facebook พึ่งพาระบบการแก้ไขอัตโนมัติระบบนี้สามารถตรวจพบและตอบสนองต่อปัญหาในระดับเครื่อง host ได้โดยอัตโนมัติ โดยการสั่งเปิด instance ใหม่ขึ้นมาทดแทน
อย่างไรก็ตาม กระบวนการแก้ไขนี้ไม่สามารถทำได้ทันที อาจใช้เวลาสักระยะในช่วงเวลานี้ backend services อาจต้องรับภาระหนักขึ้น เพราะ client พยายามร้องขอข้อมูลจาก Memcache host ที่ล่ม
วิธีทั่วไปในการรับมือกับสถานการณ์นี้คือการ rehash key และกระจาย key เหล่านั้นไปยัง server ที่ยังทำงานได้อยู่
แต่ทีมวิศวกรของ Facebook พบว่า วิธีนี้ยังเสี่ยงต่อการเกิดความล้มเหลวแบบลูกโซ่อยู่ดีเนื่องจากในระบบของพวกเขา มี key บางตัวที่ได้รับคำร้องขอจำนวนมาก (เกือบ 20% ของคำร้องขอบน server หนึ่งเครื่อง)ถ้าหาก key ที่มีโหลดสูงถูกย้ายไปยัง server อื่นในระหว่างที่เกิดความล้มเหลว ก็อาจทำให้ server ปลายทางโอเวอร์โหลด และระบบไม่เสถียรยิ่งขึ้น

การใช้เครื่อง Gutter (Gutter Machines)
เพื่อแก้ปัญหานี้ Facebook ใช้แนวทางที่เรียกว่า Gutter machinesภายในแต่ละ cluster พวกเขาจัดสรรเครื่องจำนวนหนึ่ง (โดยปกติประมาณ 1% ของ Memcache server) เพื่อเป็น Gutter machines โดยเฉพาะ
เครื่องเหล่านี้ถูกออกแบบมาให้รองรับภาระหน้าที่ของ Memcache server ที่ล้มเหลวในระหว่าง outage
การทำงานมีดังนี้:
* หาก client ของ Memcache ไม่ได้รับการตอบกลับเลย (แม้แต่ cache miss ก็ไม่มี), client จะถือว่า server นั้นล่ม และจะส่งคำร้องขอไปยัง Gutter pool
* หากคำร้องขอใน Gutter pool ได้รับผลลัพธ์เป็น cache miss, client จะดึงข้อมูลจากฐานข้อมูล และใส่ข้อมูลนั้นไว้ใน Gutter poolเพื่อให้คำร้องขอในภายหลังสามารถรับข้อมูลจาก Memcache ได้
* ข้อมูลใน Gutter จะหมดอายุเร็ว เพื่อหลีกเลี่ยงความจำเป็นในการทำ invalidation
แผนภาพด้านล่างแสดงการทำงานของ Gutter pool
แม้ว่าจะมีโอกาสที่ข้อมูลที่ถูกให้บริการจะล้าสมัย แต่ backend ก็ได้รับการปกป้องไว้และนี่คือสิ่งที่ Facebook ยอมแลกเพื่อความพร้อมใช้งานของระบบ (availability)

ความท้าทายระดับ Region (Region Level Challenges)
ในระดับ region Facebook มี frontend cluster หลายชุดที่ต้องจัดการ และความท้าทายหลักคือการทำ cache invalidation ใน Memcache ให้ทั่วถึงทุก cluster
ขึ้นอยู่กับ load balancer ผู้ใช้จะถูกเชื่อมต่อกับ frontend cluster ที่แตกต่างกันในแต่ละครั้งซึ่งนำไปสู่การที่ข้อมูลชุดเดียวกันถูก cache ซ้ำในหลาย cluster
พูดอีกแบบ คุณอาจเจอสถานการณ์ที่ key เดียวกันถูกเก็บอยู่ใน Memcached server ของหลาย cluster ภายใน region เดียวกันแผนภาพด้านล่างแสดงสถานการณ์แบบนี้
ตัวอย่างเช่น key “abc” และ “xyz” ถูกเก็บอยู่ในหลาย frontend cluster และเมื่อมีการอัปเดตค่าของ key เหล่านี้ระบบจะต้องทำ invalidation ให้ครบทุกที่ที่มันถูก cache ไว้

การทำ Invalidation ในระดับ Cluster (Cluster Level Invalidation)
การทำ invalidation ในระดับ cluster จะง่ายกว่าweb server ที่แก้ไขข้อมูลจะรับผิดชอบในการทำ invalidation ใน cluster ของตัวเอง
แนวทางนี้ทำให้สามารถรับประกัน read-after-write consistency ให้กับผู้ใช้ที่เป็นคนทำการอัปเดตนอกจากนี้ยังช่วยลดอายุของข้อมูลเก่าที่ถูก cache ไว้ใน cluster นั้นด้วย
read-after-write consistency หมายถึง ถ้าผู้ใช้ทำการแก้ไขข้อมูล เขาหรือเธอควรเห็นข้อมูลที่แก้ไขทันทีเมื่อรีโหลดหน้า

การทำ Invalidation ในระดับ Region (Region Level Invalidation)
สำหรับระดับ region, การทำ invalidation จะซับซ้อนขึ้นเล็กน้อย และ web server จะไม่เป็นคนจัดการโดยตรง
Facebook สร้าง pipeline สำหรับการทำ invalidation ที่ทำงานตามลำดับดังนี้:
* มี daemon ที่ชื่อว่า mcsqueal รันอยู่บน database server ทุกตัวภายใน storage cluster
* daemon นี้จะตรวจสอบ commit log, ดึงข้อมูลการลบ (delete) ออกมา และกระจายไปยัง Memcache ในทุก frontend cluster ภายใน region
* เพื่อประสิทธิภาพที่ดีขึ้น mcsqueal จะรวม delete หลายรายการไว้ใน packet จำนวนน้อย แล้วส่งไปยัง server ที่รัน mcrouter ในแต่ละ cluster
* mcrouter จะไล่ตรวจสอบ delete ทีละรายการภายใน batch แล้วส่งต่อไปยัง Memcache server ที่เกี่ยวข้อง
แผนภาพด้านล่างอธิบายกระบวนการนี้อย่างชัดเจน
ต่อเลยนะจากหัวข้อ "Challenges with Global Regions":

ความท้าทายเมื่อมีหลาย Region ทั่วโลก (Challenges with Global Regions)
การดำเนินงานในระดับของ Facebook ต้องการให้พวกเขาเปิดและดูแล data center ทั่วโลก
แต่การขยายระบบไปยังหลาย region ก็ทำให้เกิดความท้าทายมากขึ้น โดยเฉพาะความท้าทายที่สำคัญที่สุดคือการรักษาความสอดคล้องของข้อมูล (consistency) ระหว่างข้อมูลใน Memcache และข้อมูลใน persistent storage ที่อยู่ในหลาย region
ในการตั้งค่า region ของ Facebookหนึ่ง region จะถือครองฐานข้อมูลหลัก (primary database)ในขณะที่ region อื่น ๆ จะมีฐานข้อมูลสำเนาแบบอ่านอย่างเดียว (read-only replicas)
ฐานข้อมูลสำเนาเหล่านี้จะซิงค์กับ primary โดยใช้กลไก replication ของ MySQL
อย่างไรก็ตาม เมื่อมีการทำ replication ก็จะต้องมี replication lag หรือระยะเวลาที่ข้อมูลใน replica ยังไม่ทันกับข้อมูลใน primary
มีสองกรณีหลักที่ต้องพิจารณาเมื่อพูดถึงเรื่อง consistency:

การเขียนข้อมูลจาก Primary Region (Writes from the Primary Region)
สมมุติว่า web server ใน primary region (เช่น สหรัฐฯ) ได้รับคำร้องขอจากผู้ใช้ให้เปลี่ยนรูปโปรไฟล์
เพื่อรักษาความสอดคล้องของข้อมูล การเปลี่ยนแปลงนี้ต้องถูกเผยแพร่ไปยัง region อื่นด้วย:
* ฐานข้อมูลสำเนา (replica databases) ต้องได้รับการอัปเดต
* Memcache ใน region รอง (secondary regions) ก็ต้องถูกทำ invalidation ด้วย
ส่วนที่ยุ่งยากคือการจัดการ invalidation ให้ไปพร้อมกับกระบวนการ replication
หาก invalidation ถูกส่งไปถึง secondary region (เช่น ยุโรป) ก่อน ที่การเปลี่ยนแปลงจริงจะถูก replicate ไปถึงฐานข้อมูลใน region นั้นก็จะมีโอกาสเกิด race condition ดังนี้:
* มีผู้ใช้ในยุโรปพยายามดูรูปโปรไฟล์
* ระบบไปหาใน cache แล้วพบว่า key ถูก invalidated แล้ว
* ระบบจึงไปดึงข้อมูลจากฐานข้อมูลสำเนาที่อยู่ในยุโรป ซึ่งยังไม่ได้รับข้อมูลใหม่ → ดึงรูปเก่า
* จากนั้นระบบเอารูปเก่าไปใส่ใน cache อีกครั้ง
* เมื่อ replication สำเร็จในภายหลัง cache ก็ยังมีข้อมูลเก่าอยู่ → การเรียกดูในอนาคตก็จะยังได้รูปเก่า
แผนภาพด้านล่างแสดงลำดับเหตุการณ์นี้อย่างชัดเจน

การป้องกัน race condition
เพื่อหลีกเลี่ยง race condition แบบนี้ Facebook ใช้แนวทางที่ storage cluster ซึ่งมีข้อมูลล่าสุดที่สุดจะเป็นผู้รับผิดชอบในการส่ง invalidation ภายในแต่ละ region
แนวทางนี้ใช้ระบบ mcsqueal แบบเดียวกับที่อธิบายไว้ก่อนหน้านี้
ด้วยวิธีนี้ Facebook มั่นใจได้ว่า invalidation จะไม่ถูกส่งออกไปก่อนที่ข้อมูลจริงจะ replicate ไปถึง database ในแต่ละ region

การเขียนข้อมูลจาก Region รอง (Writes from the Non-Primary Region)
ในกรณีที่คำร้องขอการเขียน (write) มาจาก region รอง การทำงานจะมีลำดับขั้นตอนดังนี้:
* ผู้ใช้ใน region รองอัปเดตรูปโปรไฟล์ → ระบบยังให้บริการการอ่าน (read) จาก region รองได้แต่การเขียน (write) ต้องส่งไปที่ region หลัก
* เมื่อเขียนเสร็จ ข้อมูลก็จะ replicate กลับมายัง region รอง
* อย่างไรก็ตาม มีความเสี่ยงที่ก่อนที่ replication จะทันอาจมีคำร้องขอการอ่านที่มาจาก region รอง ไปดึงข้อมูลเก่าและ cache ไว้ใน Memcache
เพื่อแก้ปัญหานี้ Facebook ใช้แนวคิดที่เรียกว่า remote marker

การใช้ Remote Marker
remote marker ใช้เพื่อระบุว่าข้อมูลใน replica อาจล้าสมัย และควรดึงข้อมูลจาก region หลักแทน
วิธีการทำงานเป็นแบบนี้:
* เมื่อ web server ใน client ส่งคำร้องขอให้เปลี่ยนข้อมูลของ key K → มันจะตั้งค่า remote marker R ไว้สำหรับ key K ใน region รอง
* ต่อไป มันจะดำเนินการเขียนข้อมูลไปยัง region หลัก
* จากนั้น key K จะถูกลบออกจาก Memcache ใน region รอง
* คำร้องขอการอ่านใหม่ที่มาถึง key K ใน region รอง → จะเกิด cache miss
* ระบบตรวจสอบว่า marker R มีอยู่ไหมถ้ามี → ระบบจะเปลี่ยนไปดึงข้อมูลจาก region หลักแทน
แผนภาพด้านล่างแสดงขั้นตอนทั้งหมดนี้อย่างละเอียด

อาจฟังดูเหมือนแนวทางนี้ไม่มีประสิทธิภาพนัก เพราะมันต้อง:
1. ตรวจ cache ก่อน
2. ตรวจ remote marker ต่อ
3. แล้วจึงดึงข้อมูลจาก region หลัก
แต่ในกรณีนี้ Facebook เลือกที่จะ แลก latency สำหรับ cache missเพื่อ ลดโอกาสในการอ่านข้อมูลที่ล้าสมัย
ต่อเลยจากหัวข้อ "Single Server Optimizations":

การปรับแต่งประสิทธิภาพระดับเซิร์ฟเวอร์เดี่ยว (Single Server Optimizations)
อย่างที่คุณเห็น Facebook ได้ตัดสินใจด้านสถาปัตยกรรมหลายอย่าง เพื่อให้สามารถปรับขนาด Memcached ให้รองรับการใช้งานในระดับของพวกเขาได้
อย่างไรก็ตาม Facebook ยังใช้เวลาไม่น้อยในการปรับแต่งประสิทธิภาพของ Memcache server แต่ละเครื่องให้ดียิ่งขึ้นด้วย
แม้ว่าการปรับแต่งเหล่านี้อาจดูเล็กน้อยในภาพรวมแต่เมื่อรวมกันในระดับการใช้งานของ Facebook ผลลัพธ์ที่ได้ก็มีความสำคัญอย่างมาก
ต่อไปนี้คือการปรับแต่งที่สำคัญบางรายการ:

การขยาย Hash Table อัตโนมัติ (Automatic Hash Table Expansion)
เมื่อจำนวนข้อมูลที่จัดเก็บเพิ่มขึ้น เวลาที่ใช้ในการค้นหา (lookup) ใน hash table อาจเพิ่มขึ้นเป็น O(n) ถ้าขนาดของ table คงที่ซึ่งจะทำให้ประสิทธิภาพลดลง
Facebook จึงเพิ่มกลไกการขยายขนาด hash table แบบอัตโนมัติเมื่อจำนวนข้อมูลเกินเกณฑ์ที่กำหนด Hash table จะขยายขนาดเป็นสองเท่าโดยอัตโนมัติทำให้สามารถรักษาเวลาในการค้นหาให้อยู่ในระดับคงที่ (constant time) แม้ว่าข้อมูลจะเพิ่มขึ้นมากก็ตาม

โครงสร้างเซิร์ฟเวอร์แบบ Multi-threaded (Multi-Threaded Server Architecture)
หากใช้ thread เดียวในการให้บริการคำร้องขอจำนวนมาก จะทำให้ latency เพิ่มขึ้นและ throughput ลดลง
Facebook จึงปรับปรุง Memcache server ให้สามารถใช้หลาย thread และรองรับคำร้องขอได้พร้อมกัน (concurrent requests)

พอร์ต UDP แยกสำหรับแต่ละ thread (Dedicated UDP Port for Each Thread)
เมื่อหลาย thread ใช้พอร์ต UDP เดียวกัน อาจเกิดการแย่งใช้งาน (contention) ซึ่งจะส่งผลต่อประสิทธิภาพ
เพื่อหลีกเลี่ยงปัญหานี้ Facebook จึงปรับระบบให้แต่ละ thread มีพอร์ต UDP แยกของตัวเองทำให้แต่ละ thread ทำงานได้มีประสิทธิภาพยิ่งขึ้น

ตัวจัดการหน่วยความจำแบบ Adaptive Slab Allocator
การจัดสรรหน่วยความจำที่ไม่มีประสิทธิภาพ อาจทำให้เกิดการ fragmentation และการใช้ทรัพยากรที่ไม่เหมาะสม
Facebook จึงใช้ Adaptive Slab Allocator เพื่อจัดการ memory ภายในแต่ละ Memcache server ให้มีประสิทธิภาพมากที่สุด
slab allocator จะแบ่งหน่วยความจำที่มีอยู่เป็นชิ้นใหญ่ที่เรียกว่า slabแต่ละ slab จะถูกแบ่งเป็นหน่วยย่อยขนาดคงที่
ตัว allocator นี้จะปรับขนาดของ slab อย่าง dynamic ตามลักษณะการร้องขอของระบบ (request patterns)เพื่อให้เกิดการใช้หน่วยความจำที่เหมาะสมที่สุด

สรุป (Conclusion)
เส้นทางของ Facebook ในการปรับขนาด Memcached เป็นกรณีศึกษาที่ยอดเยี่ยมสำหรับนักพัฒนาและวิศวกร
มันแสดงให้เห็นถึงความท้าทายต่าง ๆ ที่เกิดขึ้นเมื่อคุณต้องสร้าง social network ที่มีการกระจายตัวระดับโลกซึ่งต้องรองรับข้อมูลจำนวนมหาศาล และให้บริการผู้ใช้หลายพันล้านคน
ด้วยการพัฒนาและปรับแต่ง Memcache ทั้งในระดับสถาปัตยกรรม (high-level architectural decisions)และระดับเครื่องเซิร์ฟเวอร์ (low-level server optimizations)Facebook แสดงให้เห็นถึงความสำคัญของการแก้ไขปัญหา scalability อย่างรอบด้าน
สามประเด็นหลักที่สามารถเรียนรู้ได้จากกรณีนี้คือ:
* การยอมรับแนวคิด eventual consistency เป็นกุญแจสำคัญของ performance และ availabilityแต่อย่างไรก็ตาม ทุกการตัดสินใจต้องมีความเข้าใจที่ชัดเจนในเรื่อง trade-off
* ความล้มเหลวเป็นสิ่งที่หลีกเลี่ยงไม่ได้ — จึงจำเป็นต้องออกแบบระบบให้สามารถรับมือกับความล้มเหลวได้
* การปรับแต่งระบบสามารถทำได้ในหลายระดับ และทุกระดับล้วนมีความสำคัญ

#### References:
- [blog.bytebytego.com](https://blog.bytebytego.com/p/how-facebook-served-billions-of-requests)
- [facebook.com](https://research.facebook.com/publications/scaling-memcache-at-facebook/)